# Logistical Regression
线性回归公式为: $f(x) = w^{T}x+b$  
通过激活函数$sigmoid()$将输出映射至[0, 1]内,这里认为大于等于0.5的为标签1，小于0.5的为标签0  
  
损失函数: $L = -\sum_{i}y_iln\hat{y_i} + (1-y_i)ln(1-\hat(y_i))$  
这里从两种角度来理解损失函数    
直观上, 我们希望$y_i$为1时$\hat{y_i}$也趋向于1,$y_i$为0时$\hat{y_i}$也趋向于0  
损失函数的前一项对应着$y_i=1$的损失,若$hat{y_i}=1$则损失为0。同时$y_i=1$时后一项为0,不计损失。  
同理，后一项对应着$y_i=0$的损失.    

从理论上，由于$y_i$只有两种取值${0, 1}$,因此对于第i个样本的损失函数也可以写成:  
$L_i = \hat{y_i}^{y_i}(1-\hat{y_i})^{1-y_i}$  
对所有的样本来说，构造一个极大似然函数，并使之取值最大,则有似然函数为:  
$p = \Pi_iL_i$  
两边取对数有:  
$lnp=\sum_iy_iln\hat{y_i} + (1-y_i)ln(1-\hat(y_i))$  
添加一个符号改变求最大为求最小,因此损失函数就为:  
$L = -\sum_{i}y_iln\hat{y_i} + (1-y_i)ln(1-\hat(y_i))$  
  
在具体的实现上，注意到会存在对数为0的情况，因此代码中在求损失值时，添加了一个极小值$\epsilon=1e-32$  
